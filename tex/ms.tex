% This file is part of the `speccal` project.
% Copyright 2014 the authors.
% All rights reserved.

% ## style notes:
% - all equations in `eqnarray` environments
% - use `\,` as the multiply operator!
% - parameters are `inferred`; `measurement` is reserved for data
% - use emulateapj or aastex, as you like, but watch for equation-wrapping in the former

% ---- Hogg (aastex) mode ----
%\documentclass[12pt, letterpaper, preprint]{aastex}
% ----


% ---- Charlie (emulateapj) mode ----
 \documentclass[iop,numberedappendix]{emulateapj}
 \usepackage{apjfonts}
% ----
\usepackage{color}
\bibliographystyle{apj}
\input{vc}

% math shih
\newcommand{\transpose}[1]{{#1}^{\!\mathsf T}}
\newcommand{\given}{\,|\,}
\renewcommand{\det}[1]{||{#1}||}

% affiliation marks; edit with care
\newcommand{\lick}{1}
\newcommand{\ccpp}{2}
\newcommand{\cds}{3}
\newcommand{\mpia}{4}

%figures
\usepackage{graphicx}
\DeclareGraphicsExtensions{.png,.pdf}
\newcommand{\excluster}{B192-G242}

\begin{document}\sloppy\sloppypar
\title{Combining information from photometric and spectroscopic data:\\
  Don't waste your time in spectrophotometric calibration!}
\shorttitle{don't waste your time in calibration!}
\author{
  BDJ\altaffilmark{\lick},
  DRW\altaffilmark{\lick},
  DFM\altaffilmark{\ccpp},
  DWH\altaffilmark{\ccpp, \cds, \mpia},
  CC\altaffilmark{\lick},
  others}
\shortauthors{bdj et al}
\altaffiltext{\lick}{University of California Lick Observatory}
\altaffiltext{\ccpp}{Center for Cosmology and Particle Physics, Department of Physics, New York University}
\altaffiltext{\cds}{Center for Data Science, New York University}
\altaffiltext{\mpia}{Max-Planck-Institut f\"ur Astronomie}

\begin{abstract}
In a typical spectral-fitting project,
  there tend to be a small number of bands of well-calibrated photometry
  and thousands of poorly calibrated spectroscopic pixels.
Good spectroscopic calibration is both expensive and difficult,
  but naive weighted least-square fitting will weight
  the thousands of spectroscopic pixels far higher overall
  than the few photometric bands.
Here we present a flexible and general spectroscopic calibration model,
  which can be fit simultaneously along with whatever spectral parameters.
The model involves a polynomial calibration vector to capture large-scale calibration issues
  and a Gaussian Process to capture small-scale wiggles.
We show that, in this framework, the quality of some kinds of spectral parameter fits
  is not a strong function of the quality of the spectroscopic calibration;
  that is, for many scientific goals there is no scientific reason
  to obtain good---or really any---spectrophotometric calibration.
In particular, for stellar population fitting, high signal-to-noise data,
  and good photometry,
  we show that raw counts are just as good as calibrated counts for making inferences about the
  parameters of interest.
This obviation of calibration overheads will pay \emph{all yall mad cheddar},
  at least if yall employ full cost accounting.
\end{abstract}

\keywords{
  greetings
  ---
  whole world
}

\section{Introduction}

In probabilistic inference, all information flows from the data to the
parameters of interest by means of a likelihood function, or an
expression for the probability of the data conditioned on the
parameters.
If there are $N$ independent sources of data, for each of which there
is a likelihood function, the full-data likelihood is the product of
the $N$ individual likelihoods (or the log-likelihood is a sum of the
$N$ individual log-likelihoods).
There is no bespoke ``weighting'' of the data that is justifiable in
this framework.
This creates some apparent paradoxes!
One is the following:

Imagine you have three photometric bands through which you have
observed some object (independently, say), and also a 2500-pixel
spectrum, where the pixels are defined such that they are precisely or
approximately independent measurements.
For these purposes, two spectral pixels are very close to independent
measurements if they are derived from disjoint sets of detector pixels
in the spectrograph detector plane.
Each photometric band and each spectroscopic pixel has a
log-likelihood function, and these 2503 log-likelihood functions must
be (by the Rules of Righteousness) coadded equally into one full-data
log-likelihood.
The log-likelihood is therefore fully dominated by the spectral
pixels!
This despite the fact that in almost all astronomical investigations,
the photometry is far more reliable, per measurement, than the
spectra.
That is, if the spectral pixels tend to prefer one model, or one set
of parameters, and the photometry another, the spectra will almost
always ``win'' just by their overwhelming numbers.

What is a Righteous Probabilistic Investigator (RPI) to do?
One option---fully unjustified---is to ``down-weight'' the
log-likelihoods of the spectral pixels relative to the photometric
measurements.
This is equivalent to taking the likelihoods to some power, which has
no justification in inference (though it is sometimes used in
optimization and sampling as an ``annealing'' move).
This down-weighting is not justified, but there is even more
ad-hockery than this, because there is no principled way to choose the
unprincipled weights.

The Right Thing To Do is to express the \emph{reason} that the RPI
believes the spectroscopic data to be less reliable \emph{within} the
likelihood function.
That is, the RPI must add nuisance parameters to parameterize the
unreliability of the spectroscopy, and infer those along with the
parameters of interest.
If this parameterization is good, the information in the spectroscopy
data will not flow entirely to the parameters of interest; instead,
some will flow to the nuisance parameters.
This will reduce the importance of the spectroscopy relative to the
photometry and the RPI will be well pleased with the dominance of the
photometric data in the final inferences of the parameters of
interest.
In what follows, we provide an example of this kind of
parameterization and inference.

Our example involves instantiating a ``calibration adjustment'' model,
which itself has both a polynomial component and a non-parametric
component.
The parameters of the calibration adjustment are nuisances, from a
scientific standpoint.
However, because the calibration adjustment is inferred along with the
parameters of interest, the probabilistic inference that provides
parameter estimates \emph{also} provides a spectrophotometric
calibration of the spectral data.
That is, the method we present has the potential to \emph{obviate
spectrophotometric calibration}.

We find that this potential---obviation of calibration---is realized.
That is, if the procedures demonstrated below become widely adopted,
some or perhaps most astronomical spectroscopic projects could
potentially drop or dramatically reduce their spectrophotometric
calibration programs.
This would reduce telescope overheads and data-analysis time and
complexity, delivering economic and sanity benefits to the whole
community.

\section{Model generalities}

THIS SECTION NEEDS WORK; THIS IS JUST AN EQUATION DUMP.

HOGG: A model is a parameterized likelihood function, with prior PDFs on the nuisance parameters (at least)...

HOGG: There is a likelihood for the photometry and for the spectroscopy...

HOGG: Each of these penalizes the difference between a column vector of data and a column vector of model expectation value...

The standard chi-squared or log-Gaussian log-likelihood is
\begin{eqnarray}
\ln p(d\given\theta) &=& -\frac{1}{2}\,\sum_{n=1}^N \left[\frac{[d_n - \mu_n(\theta)]^2}{\sigma_n^2} + \ln(2\pi\,\sigma_n^2) \right]
\quad ,
\end{eqnarray}
where $\theta$ is a blob of parameters of interest,
$d$ is the full set (in the form of a column vector) of data,
made up of $N$ values $d_n$,
$\mu(\theta)$ is the the column-vector mean prediction (expectation value) of the model,
made up of $N$ values $\mu_n(\theta)$,
the $\sigma_n^2$ are the observational noise variances.
We have included the $\ln(\sigma_n^2)$ term in the likelihood because
in what follows we are going to be modifying the noise model.

If you don't believe the reported data noise variances $\sigma_n^2$,
it often makes sense to add in quadrature a ``jitter'' variance $s^2$.
This is a trivial modification of the chi-squared log-likelihood:
\begin{eqnarray}\label{eq:photometricLF}
\ln p(d\given\theta,s^2) &=& -\frac{1}{2}\,\sum_{n=1}^N \left[\frac{[d_n - \mu_n(\theta)]^2}{[\sigma_n^2 + s^2]} + \ln(2\pi\,[\sigma_n^2 + s^2]) \right]
\quad .
\end{eqnarray}
This modification shows the necessity of including the log-variance
term.
This---equation~(\ref{eq:photometricLF})---is in fact the
log-likelihood function we are going to use for the photometric
measurements ({\color{blue} BDJ: IS THIS TRUE?} {\color{red} DWH,
Currently I'm not using a jitter term, but I can and will.  Update:
having difficulty with a jitter term}) in what follows.  In this
formulation, if $\theta$ are the parameters of interest, the jitter
variance $s^2$ is a nuisance noise-model parameter.  The Gaussian
Process will be a generalization of this modification.

The calibration-vector and Gaussian-Process modified log-likelihood is
\begin{eqnarray}\label{eq:spectroscopicLF}
\ln p(d\given\theta,\alpha) &=& -\frac{1}{2}\,\left[\transpose{\Delta}\,C^{-1}\,\Delta + \ln([2\pi]^N\,\det{C}) \right]
\\
\Delta &\equiv& d - f(\alpha)\ast\mu(\theta)
\\
C_{nn'} &\equiv& [\sigma_n^2 + s^2]\,\delta_{nn'} + K_\alpha(\lambda_n - \lambda_{n'})
\quad ,
\end{eqnarray}
where $\alpha$ is a blob of nuisance parameters
(which determine the jitter, the calibration vector and the kernel function),
$\Delta$ is a residual column vector,
$f(\alpha)$ is a calibration column vector,
the ``$\ast$'' operator is the pixel-wise multiplication operator,
$C$ is the Gaussian Process covariance matrix,
made up of $N^2$ values $C_{nn'}$,
$K_\alpha$ is a kernel function,
and each $\lambda_n$ is the wavelength of spectral pixel $n$.
The calibration vector $f(\alpha)$ is going to take care of the
large-scale calibration residual; the Gaussian process is going to
pick up smaller-scale residuals away from \emph{that}.
This---equation~(\ref{eq:spectroscopicLF})---is the log-likelihood we
are going to use for the spectroscopic data in what follows.

In detail, we are going to choose a $M$th-order polynomial form for
the calibration vector $f(\alpha)$ and a bell shape (Gaussian) for the
kernel function $K_\alpha(\cdot)$:
\begin{eqnarray}\displaystyle
f(\alpha) &=& c_0\,[1 + \sum_{m=1}^M c_m\,x^m]
\\
x &\equiv& \frac{\lambda}{\lambda_0} - 1
\\
K_\alpha(\lambda_n - \lambda_{n'}) &=& a^2\,\exp(-\frac{[\lambda_n - \lambda_{n'}]^2}{2\,\ell^2})
\\
\transpose{\alpha} &\equiv& \left[ \{c_m\}_{m=0}^M, s^2, a^2, \ell^2 \right]
\quad ,
\end{eqnarray}
where $\lambda$ is a column vector made up of the wavelengths $\lambda_m$
and $x$ is a scaled and shifted version of the same,
scaled by a fiducial wavelength $\lambda_0$.
Nuisance parameters $c_m$ set the shape of the large-scale calibration
issues, while $a^2$ and $\ell^2$ set the variance and correlation
length of the remaining covariant calibration noise.

\section{Experiments and Results}

We are now left to demonstrate that, by including photometry as well
as spectroscopy, it is possible to infer the parameters of interest
$\theta$ while marginalizing over the calibration parameters $\alpha$.
We will apply the methodology for spectrophotometric calibration
described above to \emph{actual, real} optical spectra of a stellar
clusters in M31.  Spectra of star clusters provide a good test case,
as they are less complex than galaxy spectra (for which it is
necessary to model the star formation history) but are by no means
trivial. In this way the key features of the calibration model and
methodology are not obscured.

To demonstrate the effectiveness of our strategy for combining
spectroscopic and photometric information we will infer the parameters
$\theta$ from a spectrum both \emph{before} and \emph{after} it has
been spectrophotometrically calibrated using typical techniques and
ancillary spectrophotometric calibration data.

\begin{figure}[h!]
\includegraphics[width = 0.5 \textwidth]{figures/dfig_b192-g242_020.png}
\caption{The calibrated (left) and uncalibrated (right) spectrum for
\excluster, along with the uncertainties (bottom panel). The spectra
have been renormalized to avoid floating point errors. {\color{blue}
SHOULD THIS SHOW ALL THE CLUSTERS OR JUST ONE?.}\label{fig:data}}
\end{figure}


\subsection{Test Data}

The data we use to test our method consist of optical spectroscopy of
XX stellar clusters in M31 for which YY-band HST photometric data
exist.  The optical spectra were obtained using the fiber-fed
Hectoscpec intrument on MMT by \citet{caldwell}.  The wavelength range
of the spectra is $3700-9100 \AA$. The instrumental resolution is
$\sim 5\AA$ across the optical range \citep{fabricant13}.  {\color{blue} Wavelength
calibration happened. Sky subtraction happened.} The data were
approximately spectrophotometrically calibrated using an average
calibration vector for the night constructed from {\color{blue} MORE
HERE. Discuss S/N, sky subtraction.}


An example spectrum, both after and before spectrophotometric
calibration, is shown in Figure \ref{fig:data}.  When fitting the
spectra we mask the region around the bright OI5577 sky line, and we
fit only to the spectrum with $3750 < \lambda < 7200$ to avoid the low
S/N edges and, on the red side, imperfect sky line subtraction in a
region of the spectrum that has a paucity of informative spectral
lines. Furthermore, the MILES spectral library (see
\S\ref{sec:cluster_model}) only extends to $\lambda < 7500$\AA.
{\color{red} Specify/Justify order of calibration polynomial here?}.

{\color{blue} DRW words about photometry}

\begin{table}[h!]
\caption{List all the clusters, RA, Dec, photometry and individual exposures.}
\end{table}

\subsection{Star Cluster Model}
We model the stellar cluster as a single age SSP. The spectrum of a
star cluster under this assumption is given by
\begin{eqnarray}\displaystyle
F_{\theta^\prime}(\lambda_o) & = &
\frac{m_*}{4\pi d_L^2(1+z)} \, S(\lambda, t, Z , \beta) \, e^ {-k_\lambda\tau_V} \\
\nonumber \\ 
\lambda_o & = & (1+z)\,\lambda 
\\
\theta^\prime & \equiv & \left[ m_*, t, Z, \tau_V, z, d_L, \beta \right]
\quad ,
\end{eqnarray} where the
parameters $\theta^\prime$ include 
the stellar mass $m_*$, 
effective optical depth to dust in the $V$-band $\tau_V$, 
luminosity distance $d_L$,
and redshift $z$.  
The observed frame wavelengths $\lambda_o$ are related to the restframe
wavelengths $\lambda$ in the usual way.

The spectrum of one solar mass of stars that formed at lookback time
$t$ with metallicity $Z$ is given by $S(\lambda, t, Z [, \beta])$.
Here the additional parameters $\beta$ may include details of the
population synthesis model, such as the IMF slope and adjustments to
the stellar spectra or stellar evolutionary tracks. We will assume
$\beta$ to be fixed for the purposes of this exercise, with no loss of
generality {\color{blue} (KEEPING IMF SLOPE CONSTANT)}.  We will also fix the
shape of the attenuation curve, $k_\lambda \equiv
\tau_\lambda/\tau_V$, to the Milky way average of \citet{CCM89} with
$R_V=3.1$ and assume that $d_L$ is known to high precision from
independent methods and can therefore be treated as fixed.  In
practice, $d_L$ is completely degenerate with $m_*$. We calculate
$S(\lambda, t, Z)$ using the Flexible Stellar Population Synthesis
code \citep[FSPS][]{FSPS}.  We use the Padova isochrones
\citep{Padova} and the MILES stellar spectral library \citep{MILES}.

The model spectra $F_{\theta^\prime}$ are smoothed by convolution
with a Gaussian in wavelength space (in this case to model the MMT
line-spread function) and are interpolated to the wavelength points of
the of the observed spectrum while taking into account the
redshift. The instrumental resolution is given by the parameter
$\sigma$.  {\color{blue}Discuss intrinsic resolution of model spectra
(MILES), what to do in situations where instrumental resolution is
higher, lower or comparable (ouch) to intrinsic velocity broadening.}

Nebular emission lines (which may arise from HII regions around the
clusters or from diffuse ionized gas) and interstellar absorption
lines are modeled as a sum of Gaussians of unknown amplitude $A_\ell$,
all of the same width $\sigma_e$ (which need not be the same as
stellar broadening $\sigma$) and with known central wavelengths
$\lambda_\ell$.  For emission lines the amplitudes are constrained to
be positive, while for interstellar absorption (e.g. Na D and Ca K)
the amplitudes are constrained to be negative. This framework can be
easily extended to include more complex models for the nebular
emission, such as allowing line dependent widths and velocities, and
using Voight profiles for the line shapes.  

The final mean model is then given by 
\begin{eqnarray}\label{eq:MeanModel} 
\mu(\theta) &  = & (G_\sigma  \otimes F_{\theta^\prime})(\lambda) +
\sum_{\ell=0}^{N_\ell} S_\ell \\
S_\ell & = & \frac{A_\ell}{\sigma_e\sqrt{2\pi}} \exp(-\frac{(\lambda -
 \lambda_\ell)^2}{2\sigma_e^2})\\
\theta & \equiv & \left[ \{\theta^\prime\}, \sigma, \{A_\ell\}_{\ell=0}^{N_l},
  \sigma_e \right]
\quad ,
\end{eqnarray}
where $G_\sigma$ represents a Gaussian of unit area 
and standard deviation $\sigma$, 
$\otimes$ indicates convolution, 
and the full parameter set $\theta$ now includes
the instrumental wavelength broadening $\sigma$ 
and the dispersion $\sigma_e$ and
amplitudes $A_\ell$ of the $N_l$ nebular emission and interstellar
absorption lines.
This is the mean model which appears in equation
\ref{eq:SpectroscopicLF}.

To model the photometry we simply project the observed frame mean
model spectrum (equation \ref{eq:MeanModel}) onto the filters of
interest.  Note that we do \emph{not} include the calibration vector
$f(\alpha)$ in this projection.


\subsection{Sampling and Priors}

We estimate the posterior through MCMC sampling after an initial round
of optimization using Powell's method.  The specific sampling
algorithm we use is the affine-invariant ensemble sampling scheme of
\citet{GW}, as implemented in the \texttt{emcee} package \cite{dfm}
Unlike typical Metropolis-Hastings MCMC sampling, the affine-invariant
sampler does not require the specification of step sizes in each
dimension.  {\color{blue}ASSESSING SAMPLER CONVERGENCE}
 
Our prior distributions are in all cases top-hat functions, described
in Table \ref{tbl:priors}, though more informative prior distributions
may be used.  Informative priors may be especially appropriate for the
calibration parameters $\alpha$ if additional information about the
instrument is available; or for the parameters of interest $\theta$,
for example in the case that there is knowledge of the metallicity
distribution of the population from which a given cluster is drawn.

\input{tables/priors.tbl}

\begin{figure*}[h!]
\includegraphics[width=\textwidth]{figures/sfig_b192-g242_020_cal.png}
\caption{Spectra resulting from draws from the posterior parameter
space conditioned on the calibrated \excluster~ spectrum and
photometry.  Left: For each of 5 draws from the posterior we show from
top to bottom, three components of the model: the mean cluster
spectrum, the calibration vector, and the mean prediction of $\Delta$
for the Gaussian process.  Right: From top to bottom, the full model
({\it cyan}) compared to the observed, calibrated spectrum ({\it
magenta}), the ratio of the observed to the modeled spectrum, and the
difference between the observed spectrum and the modeled spectrum
normalized by the uncertainty.
\label{fig:inferred_spectrum}}
\end{figure*}


\subsection{Results}

We first infer the parameters of interest $\theta$ for a calibrated
spectrum of one of the clusters, \excluster, using the full YY-band
photometry. In Figure \ref{fig:inferred_spectrum} we show the spectra
that result from draws of the parameters $[\theta,\alpha]$ from the
posterior distribution, as well as several of the individual
components of the model constructed from each draw. Figure
\ref{fig:inferred_spectrum} also shows the calibrated spectrum on
which the priors were conditioned, and residuals between the posterior
models and the observed data.  The agreement is quite good, though
some lines are not accurately predicted.  For example, the observed
Mg$b$ absorption appears stronger than the modeled absorption.

In Figure \ref{fig:inferred_sed} we show the corresponding SED for the
posterior parameter draws, compared to the observed SED. There is some
tension between the modeled and observed SEDs, I'm not quite sure
why. Finally, In Figure \ref{fig:inferred_params} we show the
marginalized and joint PDFs for a subset of the full model parameters.


\begin{figure}[h!]
\includegraphics[width=0.5\textwidth]{figures/pfig_b192-g242_020_cal.png}
\caption{Model SEDs.  Top: The model photometric SED resulting from draws from the posterior
  parameter space conditioned ({\it cyan}) on the observed photometry
  ({\it magenta})  and spectra.  Bottom: uncertainty normalized
  residuals of the models from the observations. 
 . \label{fig:inferred_sed}}
\end{figure}

\begin{figure}[h!]
\includegraphics[width=0.5\textwidth]{figures/ptri_b192-g242_020_cal.png}
\caption{ Marginalized and joint PDFs of  subset of the physical
  parameters $\theta$ inferred from the spectophotometrically
  calibrated spectrum of \excluster. The blue lines indicate the
  parameter values that resulted from the powell minimization. \label{fig:inferred_params}}
\end{figure}

The physical model parameters that we infer indicate that \excluster~
has super-solar metallicity, an age of $\sim 225$ Myr, moderate dust
extinction, and a stellar mass of $\sim 10^{4}$ M$_{sun}$ {\color{blue}
check that this is current mass, not initial mass}.  We find a spectral
broadening of $\sim 1.75$\AA (4.1\AA FWHM), which when combined in
quadrature with the intrinsic resolution of the MILES library, 2.5\AA
FWHM \citep{beifiori11}, reproduces the typical line-spread function
of the MMT Hectospec instrument, $\sim 5.0$\AA \citep{fabricant13}.
We obtain strong constraints on the systemic velocity.

For the calibration model, we obtain a vector $f(\alpha)$
that is nearly linear in wavelength {\color{red} WHY IS IT NOT A
CONSTANT?  Need longer burn-in?  Is this the same issue as the SED
residuals?}.  The length scale of the Gaussian process is $\sim
60$\AA.  It is possible to reconstruct the inferred total
multiplicative calibration vector for each draw of the model
parameters.  Rearranging equation \ref{eq:spectroscopicLF} yields
\begin{eqnarray} 
\frac{d}{\mu(\theta)} & = & f(\alpha) +
\frac{\tilde{\Delta}}{\mu(\theta)}
\quad ,
\end{eqnarray}
for the total effective multiplicative calibration, where
$\tilde{\Delta}$ is now the Gaussian process mean prediction for the
residual between the data and the model. The inverse of this ratio is
shown in the left panel of Figure \ref{fig:inferred_calib} as our
inferred total multiplicative calibration function; if the
spectrophotometric calibration were perfect and we had correctly
inferred it, then we would expect this vector to be constant as a
function of wavelength.


\begin{figure*}[h!]
\includegraphics[width=\textwidth]{figures/cfig_b192-g242_020.png}
\caption{Left: Samples of the effective multiplicative calibration
  vector for the spectrophotometrically calibrated spectrum of
  \excluster~ ({\it cyan}) compared to that obtained from ancillary
  photometric data ({\it magenta}).  Right:  The same, but for the
  uncalibrated data. 
 \label{fig:inferred_calib}}
\end{figure*}

BDJ: Next, we infer the parameters of the spectrum of the same cluster
\emph{without} spectrophotometric calibration.  How many/which figures
to show?

BDJ: Then, we show select marginalized or joint PDFs for each cluster
calibrated/uncalibrated, to assess consistency.  Or we just show
comparisons of confidence intervals.

\begin{figure}[h!]
\includegraphics[width =0.5\textwidth]{figures/B192_020_cratio.pdf}
\caption{Money plot.  Show the difference between the parameters
  inferred from the calibrated and uncalibrated spectra, for each
  cluster. Tjis is a placeholder, since it only shows B192 for fixed
  GP parameters. \label{fig:boom}}
\end{figure}

\subsection{Dependence on Photometric Data}
In this section we examine how the constraints on physical (and
calibration) parameters vary as a function of the number and type of
photometric points available. {\color{red} BDJ DO THIS TEST.}

\section{Discussion}

We have demonstrated, using a sample of stellar clusters in M31, that
we can combine photometric and spectroscopic data in a principled way
to infer physical properties.  We do not resort to an arbitrary
down-weighting or up-weighting of certain data. Instead, we explicitly
model our uncertain knowledge of the spectral calibration and infer
this calibration jointly with the physical properties. For a number of
applications this combination of spectroscopy and photometry reduces
the need for spectrophotometric calibration.  Calibration information,
if it exists, can be incorporated into informative priors on the
calibration parameters of the model.

Our strategy is easily extensible to more complicated models, which
include for example night sky-line emission in the spectroscopy (or
residuals from an intial sky-line subtraction), and uncertainties in
wavelength calibration. {\color{blue} DISCUSS MORE COMPLICATED
COVARIANCE KERNELS, MULTIPLE KERNELS, etc.  MODEL CHECKING.}

In a heirarchical modelling context it should be possible to use the
inferred calibration parameters, along with additional information
about the observations (e.g. airmass, instrument temperature), to in
turn infer the parameters of a generative model for the
calibration. This generative model can then be used in the
(probabilistic) calibration of objects where the spectra are difficult
to model explicitly.

Limitations.  The strategy we have advocated has several limitations.
First, it requires a generative model for the spectrum of the object
of interest, and is thus ill-suited to discovery projects.  Second,
care must be taken to avoid absorbing interesting model deficiencies
into the calibration model.  Third, we have made the assumption that
the spectroscopy and the photometry are sampling the same populations.
In practice, differences between spectroscopic and photometric
apertures often mean that the photometry and the spectroscopy are sampling
slightly different physical regions.  The correct response to this
situation is to explicitly model the differences, incorporating prior
information about the spatial variation of physical properties.
Finally, this method is computationally intensive and expensive, since
we are constantly inverting largish matrices.

BDJ misc issues, collected here in case we want to address them and to
keep me from cluttering up the main text: Model resolution and
instrument resolution.  How to interpret GP residuals, as a fn of S/N?
Photometric upper limits? Infer the wavelength solution as well -
stellar population (and telluric lines) as your arc. Combinations of
broadening in velocity space (physical) and in wavelength space
(instrumental)

HOGG COMPUTE TOTAL ANNUAL COST OF SPECTROPHOTOMETRY (to astronomical community).

All the code used in this project is available under an open-source license
  from \url{http://github.com/bd-j/bsfh/}.
This version of the paper was generated
  from a git repository available at \url{http://github.com/bd-j/speccal/}
  with git hash \texttt{\githash\,(\gitdate)}.

\acknowledgements
Thanks to X. for bringing us beer.
DRW is supported by NASA through Hubble Fellowship grant
  HST-HF-51331.01 awarded by the Space Telescope Science Institute.
BDJ and DRW acknowledge the hospitality of Hans-Walter Rix and the MPIA. 
CC is supported by Packard and Sloan Foundation Fellowships. 
This research made extensive use of NASA's Astrophysics Data System Bibliographic Services. 
In large part, analysis and plots presented in this paper utilized
  iPython and packages from NumPy, SciPy, and Matplotlib
  \citep[][]{hunter2007, oliphant2007, perez2007, astropy2013} as well
  as python-FSPS  (http:://github.com/dfm/python-fsps) .


\end{document}
