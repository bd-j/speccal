% This file is part of the `speccal` project.
% Copyright 2014 the authors.
% All rights reserved.

% ## style notes:
% - all equations in `eqnarray` environments
% - use `\,` as the multiply operator!
% - parameters are `inferred`; `measurement` is reserved for data
% - use emulateapj or aastex, as you like, but watch for equation-wrapping in the former

% ---- Hogg (aastex) mode ----
\documentclass[12pt, letterpaper, preprint]{aastex}
% ----

% ---- Charlie (emulateapj) mode ----
% \documentclass[iop,numberedappendix]{emulateapj}
% \usepackage{apjfonts}
% ----

\bibliographystyle{apj}
\input{vc}

% math shih
\newcommand{\transpose}[1]{{#1}^{\!\mathsf T}}
\newcommand{\given}{\,|\,}
\renewcommand{\det}[1]{||{#1}||}

% affiliation marks; edit with care
\newcommand{\lick}{1}
\newcommand{\ccpp}{2}
\newcommand{\cds}{3}
\newcommand{\mpia}{4}

\begin{document}\sloppy\sloppypar
\title{Combining information from photometric and spectroscopic data:\\
  Don't waste your time in spectrophotometric calibration!}
\shorttitle{don't waste your time in calibration!}
\author{
  BDJ\altaffilmark{\lick},
  DRW\altaffilmark{\lick},
  DFM\altaffilmark{\ccpp},
  DWH\altaffilmark{\ccpp, \cds, \mpia},
  CC\altaffilmark{\lick},
  others}
\shortauthors{bdj et al}
\altaffiltext{\lick}{University of California Lick Observatory}
\altaffiltext{\ccpp}{Center for Cosmology and Particle Physics, Department of Physics, New York University}
\altaffiltext{\cds}{Center for Data Science, New York University}
\altaffiltext{\mpia}{Max-Planck-Institut f\"ur Astronomie}

\begin{abstract}
In a typical spectral-fitting project,
  there tend to be a small number of bands of well-calibrated photometry
  and thousands of poorly calibrated spectroscopic pixels.
Good spectroscopic calibration is both expensive and difficult,
  but naive weighted least-square fitting will weight
  the thousands of spectroscopic pixels far higher overall
  than the few photometric bands.
Here we present a flexible and general spectroscopic calibration model,
  which can be fit simultaneously along with whatever spectral parameters.
The model involves a polynomial calibration vector to capture large-scale calibration issues
  and a Gaussian Process to capture small-scale wiggles.
We show that, in this framework, the quality of some kinds of spectral parameter fits
  is not a strong function of the quality of the spectroscopic calibration;
  that is, for many scientific goals there is no scientific reason
  to obtain good---or really any---spectrophotometric calibration.
In particular, for stellar population fitting, high signal-to-noise data,
  and good photometry,
  we show that raw counts are just as good as calibrated counts for making inferences about the
  parameters of interest.
This obviation of calibration overheads will pay \emph{all yall mad cheddar},
  at least if yall employ full cost accounting.
\end{abstract}

\keywords{
  greetings
  ---
  whole world
}

\section{Introduction}

In probabilistic inference, all information flows from the data to the
parameters of interest by means of a likelihood function, or an
expression for the probability of the data conditioned on the
parameters.
If there are $N$ independent sources of data, for each of which there
is a likelihood function, the full-data likelihood is the product of
the $N$ individual likelihoods (or the log-likelihood is a sum of the
$N$ individual log-likelihoods).
There is no bespoke ``weighting'' of the data that is justifiable in
this framework.
This creates some apparent paradoxes!
One is the following:

Imagine you have three photometric bands through which you have
observed some object (independently, say), and also a 2500-pixel
spectrum, where the pixels are defined such that they are precisely or
approximately independent measurements.
For these purposes, two spectral pixels are very close to independent
measurements if they are derived from disjoint sets of detector pixels
in the spectrograph detector plane.
Each photometric band and each spectroscopic pixel has a
log-likelihood function, and these 2503 log-likelihood functions must
be (by the Rules of Righteousness) coadded equally into one full-data
log-likelihood.
The log-likelihood is therefore fully dominated by the spectral
pixels!
This despite the fact that in almost all astronomical investigations,
the photometry is far more reliable, per measurement, than the
spectra.
That is, if the spectral pixels tend to prefer one model, or one set
of parameters, and the photometry another, the spectra will almost
always ``win'' just by their overwhelming numbers.

What is a Righteous Probabilistic Investigator (RPI) to do?
One option---fully unjustified---is to ``down-weight'' the
log-likelihoods of the spectral pixels relative to the photometric
measurements.
This is equivalent to taking the likelihoods to some power, which has
no justification in inference (though it is sometimes used in
optimization and sampling as an ``annealing'' move).
This down-weighting is not justified, but there is even more
ad-hockery than this, because there is no principled way to choose the
unprincipled weights.

The Right Thing To Do is to express the \emph{reason} that the RPI
believes the spectroscopic data to be less reliable \emph{within} the
likelihood function.
That is, the RPI must add nuisance parameters to parameterize the
unreliability of the spectroscopy, and infer those along with the
parameters of interest.
If this parameterization is good, the information in the spectroscopy
data will not flow entirely to the parameters of interest; instead,
some will flow to the nuisance parameters.
This will reduce the importance of the spectroscopy relative to the
photometry and the RPI will be well pleased with the dominance of the
photometric data in the final inferences of the parameters of
interest.
In what follows, we provide an example of this kind of
parameterization and inference.

Our example involves instantiating a ``calibration adjustment'' model,
which itself has both a polynomial component and a non-parametric
component.
The parameters of the calibration adjustment are nuisances, from a
scientific standpoint.
However, because the calibration adjustment is inferred along with the
parameters of interest, the probabilistic inference that provides
parameter estimates \emph{also} provides a spectrophotometric
calibration of the spectral data.
That is, the method we present has the potential to \emph{obviate
spectrophotometric calibration}.

We find that this potential---obviation of calibration---is realized.
That is, if the procedures demonstrated below become widely adopted,
some or perhaps most astronomical spectroscopic projects could
potentially drop or dramatically reduce their spectrophotometric
calibration programs.
This would reduce telescope overheads and data-analysis time and
complexity, delivering economic and sanity benefits to the whole
community.

\section{Model generalities}

THIS SECTION NEEDS WORK; THIS IS JUST AN EQUATION DUMP.

HOGG: A model is a parameterized likelihood function, with prior PDFs on the nuisance parameters (at least)...

HOGG: There is a likelihood for the photometry and for the spectroscopy...

HOGG: Each of these penalizes the difference between a column vector of data and a column vector of model expectation value...

The standard chi-squared or log-Gaussian log-likelihood is
\begin{eqnarray}
\ln p(d\given\theta) &=& -\frac{1}{2}\,\sum_{n=1}^N \left[\frac{[d_n - \mu_n(\theta)]^2}{\sigma_n^2} + \ln(2\pi\,\sigma_n^2) \right]
\quad ,
\end{eqnarray}
where $\theta$ is a blob of parameters of interest,
$d$ is the full set (in the form of a column vector) of data,
made up of $N$ values $d_n$,
$\mu(\theta)$ is the the column-vector mean prediction (expectation value) of the model,
made up of $N$ values $\mu_n(\theta)$,
the $\sigma_n^2$ are the observational noise variances.
We have included the $\ln(\sigma_n^2)$ term in the likelihood because
in what follows we are going to be modifying the noise model.

If you don't believe the reported data noise variances $\sigma_n^2$,
it often makes sense to add in quadrature a ``jitter'' variance $s^2$.
This is a trivial modification of the chi-squared log-likelihood:
\begin{eqnarray}\label{eq:photometricLF}
\ln p(d\given\theta,s^2) &=& -\frac{1}{2}\,\sum_{n=1}^N \left[\frac{[d_n - \mu_n(\theta)]^2}{[\sigma_n^2 + s^2]} + \ln(2\pi\,[\sigma_n^2 + s^2]) \right]
\quad .
\end{eqnarray}
This modification shows the necessity of including the log-variance
term.
This---equation~(\ref{eq:photometricLF})---is in fact the
log-likelihood function we are going to use for the photometric
measurements (BDJ: IS THIS TRUE?  DWH, Currently I'm not using a
jitter term, but I can and will) in what follows.  In this
formulation, if $\theta$ are the parameters of interest, the jitter
variance $s^2$ is a nuisance noise-model parameter.  The Gaussian
Process will be a generalization of this modification.

The calibration-vector and Gaussian-Process modified log-likelihood is
\begin{eqnarray}\label{eq:spectroscopicLF}
\ln p(d\given\theta,\alpha) &=& -\frac{1}{2}\,\left[\transpose{\Delta}\,C^{-1}\,\Delta + \ln([2\pi]^N\,\det{C}) \right]
\\
\Delta &\equiv& d - f(\alpha)\ast\mu(\theta)
\\
C_{nn'} &\equiv& [\sigma_n^2 + s^2]\,\delta_{nn'} + K_\alpha(\lambda_n - \lambda_{n'})
\quad ,
\end{eqnarray}
where $\alpha$ is a blob of nuisance parameters
(which determine the jitter, the calibration vector and the kernel function),
$\Delta$ is a residual column vector,
$f(\alpha)$ is a calibration column vector,
the ``$\ast$'' operator is the pixel-wise multiplication operator,
$C$ is the Gaussian Process covariance matrix,
made up of $N^2$ values $C_{nn'}$,
$K_\alpha$ is a kernel function,
and each $\lambda_n$ is the wavelength of spectral pixel $n$.
The calibration vector $f(\alpha)$ is going to take care of the
large-scale calibration residual; the Gaussian process is going to
pick up smaller-scale residuals away from \emph{that}.
This---equation~(\ref{eq:spectroscopicLF})---is the log-likelihood we
are going to use for the spectroscopic data in what follows.

In detail, we are going to choose a $M$th-order polynomial form for
the calibration vector $f(\alpha)$ and a bell shape (Gaussian) for the
kernel function $K_\alpha(\cdot)$:
\begin{eqnarray}\displaystyle
f(\alpha) &=& c_0\,[1 + \sum_{m=1}^M c_m\,x^m]
\\
x &\equiv& \frac{\lambda}{\lambda_0} - 1
\\
K_\alpha(\lambda_n - \lambda_{n'}) &=& a^2\,\exp(-\frac{[\lambda_n - \lambda_{n'}]^2}{2\,\ell^2})
\\
\transpose{\alpha} &\equiv& \left[ \{c_m\}_{m=0}^M, s^2, a^2, \ell^2 \right]
\quad ,
\end{eqnarray}
where $\lambda$ is a column vector made up of the wavelengths $\lambda_m$
and $x$ is a scaled and shifted version of the same,
scaled by a fiducial wavelength $\lambda_0$.
Nuisance parameters $c_m$ set the shape of the large-scale calibration
issues, while $a^2$ and $\ell^2$ set the variance and correlation
length of the remaining covariant calibration noise.

\section{Experiments and Results}

We are now left to demonstrate that it is possible to infer the
parameters of interest $\theta$ while marginalizing over the
calibration parameters $\alpha$.  We will apply the methodology for
spectrophotometric calibration described above to \emph{actual,
real} optical spectra of a stellar clusters in M31.  Spectra of star
clusters provide a good test case, as they are less complex than
galaxy spectra (for which it is necessary to model the star formation
history) but are by no means trivial. In this way the key features of
the calibration model and methodology are not obscured.  

To demonstrate the effectiveness of our strategy for combining
spectroscopic and photometric information we will infer the parameters
$\theta$ from a spectrum both \emph{before} and \emph{after} it has
been spectrophotometrically calibrated using typical techniques and
ancillary spectrophotometric calibration data.

\subsection{Test Data}

DRW/BDJ WORDS ABOUT DATA

The data we use to test our method consists of optical spectroscopy of
XX stellar clusters in M31 for which YY-band HST photometric data
exist.  The optical spectra were obtained using the fiber-fed
Hectoscpec intrument on MMT by \citet{caldwell}.  The wavelength range
of the spectra is $3700-7200 \AA$. The instrumental resolution is
$\sim 5\AA$ across the optical range \citep{fabricant13}.  Wavelength
calibration happened. Sky subtraction happened. The data were
approximately spectrophotometrically calibrated using an average
calibration vector for the night constructed from.... (MORE
HERE). Figure \ref{fig:data} shows the spectra before and after
calibration (SHOULD THIS SHOW ALL THE CLUSTERS OR JUST ONE?).  Discuss
S/N, sky subtraction.

\begin{figure}[h!]
\caption{Shows the calibrated and uncalibrated spectrum for one
  cluster, along with the uncertainty spectrum and (maybe) the
  calibration vector. \label{fig:data}}
\end{figure}


\begin{table}[h!]
\caption{List all the clusters, and individual exposures.}
\end{table}

\subsection{Star Cluster Model}
We model the stellar cluster as a single age SSP. The spectrum of a
star cluster under this assumption is given by
\begin{eqnarray}\displaystyle
F_{\theta^\prime}(\lambda_o) & = &
\frac{m_*}{4\pi d_L^2(1+z)} \, S(\lambda, t, Z , \beta) \, e^ {-k_\lambda\tau_V} \\
\nonumber \\ 
\lambda_o & = & (1+z)\,\lambda 
\\
\theta^\prime & \equiv & \left[ m_*, t, Z, \tau_V, z, d_L, \beta \right]
\quad ,
\end{eqnarray} where the
parameters $\theta^\prime$ include 
the stellar mass $m_*$, 
effective optical depth to dust in the $V$-band $\tau_V$, 
luminosity distance $d_L$,
and redshift $z$.  
The observed frame wavelengths $\lambda_o$ are related to the restframe
wavelengths $\lambda$ in the usual way.

The spectrum of one solar mass of stars that formed at lookback time
$t$ with metallicity $Z$ is given by $S(\lambda, t, Z [, \beta])$.
Here the additional parameters $\beta$ may include details of the
population synthesis model, such as the IMF slope and adjustments to
the stellar spectra or stellar evolutionary tracks. We will assume
$\beta$ to be fixed for the purposes of this exercise, with no loss of
generality (KEEPING IMF SLOPE CONSTANT FOR NOW).  We will also fix the
shape of the attenuation curve, $k_\lambda \equiv
\tau_\lambda/\tau_V$, to the Milky way average of \citet{CCM89} with
$R_V=3.1$ and assume that $d_L$ is known to high precision from
independent methods and can therefore be treated as fixed.  In
practice, $d_L$ is completely degenerate with $m_*$. We calculate
$S(\lambda, t, Z)$ using the Flexible Stellar Population Synthesis
code \citep[FSPS][]{FSPS}.  We use the Padova isochrones
\citep{Padova} and the MILES stellar spectral library \citep{MILES}.

BDJ IMPROVE DISCUSSION OF BROADENING.  The model spectra are smoothed
by convolution with a Gaussian in wavelength space (to model the MMT
line-spread function) and are interpolated to the wavelength points of
the of the observed spectrum while taking into account the
redshift. The instrumental resolution is given by $\sigma$.

Nebular emission lines (which may arise from HII regions around the
clusters or from diffuse ionized gas) and interstellar absorption
lines are modeled as a sum of Gaussians of unknown amplitude $A_\ell$,
all of the same width $\sigma_e$ (which need not be the same as
stellar broadening $\sigma$) and with known central wavelengths
$\lambda_\ell$.  For emission lines the amplitudes are constrained to be
positive, while for interstellar absorption (e.g. Na D and Ca K) the
amplitudes are constrained to be negative. This framework can be
easily extended to include more complex models for the nebular
emission, such as allowing line dependent widths and velocities.

The final mean model is then given by 
\begin{eqnarray}\label{eq:MeanModel} 
\mu(\theta) &  = & (G_\sigma  \otimes F_{\theta^\prime})(\lambda) +
\sum_{\ell=0}^{N_\ell} S_\ell \\
S_\ell & = & \frac{A_\ell}{\sigma_e\sqrt{2\pi}} \exp(-\frac{(\lambda -
 \lambda_\ell)^2}{2\sigma_e^2})\\
\theta & \equiv & \left[ \{\theta^\prime\}, \sigma, \{A_\ell\}_{\ell=0}^{N_l},
  \sigma_e \right]
\quad ,
\end{eqnarray}
where $G_\sigma$ represents a Gaussian of unit area 
and standard deviation $\sigma$, 
$\otimes$ indicates convolution, 
and the full parameter set $\theta$ now includes 
the dispersion $\sigma_e$ and
amplitudes $A_\ell$ of the $N_l$ nebular and interstellar emission
lines. 

To model the photometry we simply project the observed frame mean
model spectrum (equation \ref{eq:MeanModel}) onto the filters of
interest.  Note that we do \emph{not} include the calibration vector
$f(\alpha)$ in this projection.


\subsection{Sampling and Priors}

We estimate the posterior through MCMC sampling after an initial round
of optimization using Powell's method.  The specific sampling
algorithm we use is the affine-invariant ensemble sampling scheme of
\citet{GW}, as implemented in the \texttt{emcee} package \cite{dfm}
Unlike typical Metropolis-Hastings MCMC sampling, the affine-invariant
sampler does not require the specification of step sizes in each
dimension.  ASSESSING SAMPLER CONVERGENCE
 
Our prior distributions are in all cases top-hat functions, though
more informative prior distributions may be used.  Informative priors
may be especially appropriate for the calibration parameters $\alpha$
if additional information about the instrument is available or for the
parameters of interest $\theta$, for example in the case that there
is knowledge of the metallicity distribution of the population from
which a given cluster is drawn.

\begin{table}[h!]
\caption{List the parameters and  their allowed ranges.}
\end{table}

\subsection{Results}

We first infer the parameters of interest $\theta$ for a calibrated
spectrum of one of the clusters, using the full YY-band photometry. In
Figure \ref{fig:calibrated_spectrum} we show the spectrum resulting
from draws of the parameters $[\theta,\alpha]$ from the posterior
distribution.  This figure also shows the calibrated spectrum on which
the priors were conditioned, and several of the individual components
of the model constructed from each draw.  In Figure
\ref{fig:calibrated_spectrum} we also show the residuals between the data
and the draws from the posterior, for both the spectra and the
photometry. In Figure \ref{fig:calibrated_triangle} we show the
marginalized and joint PDFs for the parameters.

BDJ: Discuss degeneracies, etc.  Apparently we get really nice
redshift/velocity constraints for free.

BDJ: Next, we infer the parameters of the spectrum of the same cluster
\emph{without} spectrophotometric calibration.

BDJ: Then, we show select marginalized or joint PDFs for each cluster
calibrated/uncalibrated, to assess consistency.  They are very consistent.

BDJ: Finally, we have fun playing with the number of photometric bands
and the S/N.

\begin{figure}[h!]
\caption{Show, for one cluster, the (un)calibrated spectral data, draws from
  the posterior for the model, and residuals}
\end{figure}

\begin{figure}[h!]
\caption{Show the observed photometric SED and draws from the
  posterior, for one cluster.}
\end{figure}

\begin{figure}[h!]
\caption{Show a corner plot of selected relevant parameters, for one cluster.}
\end{figure}

\begin{figure}[h!]
\caption{Money plot.  Show the difference between the parameters
  inferred from the calibrated and uncalibrated spectra, for each cluster.}
\end{figure}

\section{Discussion}

BDJ INSERT WORDS HERE.
BDJ random issues, collected here in case we want to address them and
to keep me from cluttering up the main text: effective aperture
corrections (i.e. we're implicitly assuming photometry and
spectroscopy sample the same population).  Sky subtraction residuals.
Model resolution and instrument resolution.  Method only useful when
you have a model for the mean spectrum?  How to interpret GP
residuals, as a fn of S/N?  Photometric upper limits? Infer the
wavelength solution as well - stellar population (and telluric lines)
as your arc. Combinations of broadening in velocity space (physical)
and in wavelength space (instrumental)

HOGG COMPUTE TOTAL ANNUAL COST OF SPECTROPHOTOMETRY (to astronomical community).

All the code used in this project is available under an open-source license
  from \url{http://github.com/bd-j/bsfh/}.
This version of the paper was generated
  from a git repository available at \url{http://github.com/bd-j/speccal/}
  with git hash \texttt{\githash\,(\gitdate)}.

\acknowledgements
Thanks to X. for bringing us beer.

\end{document}
